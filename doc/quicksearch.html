<html>
<head>
</head>
<body style="background: transparent;">
    <script src="scripts/docstrap.lib.js"></script>
    <script src="scripts/lunr.min.js"></script>
    <script src="scripts/fulltext-search.js"></script>

    <script type="text/x-docstrap-searchdb">
    {"main.js.html":{"id":"main.js.html","title":"Source: main.js","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Source: main.js define([ 'dojo/_base/declare', 'dojo/_base/lang', 'dojo/query', 'prakalpa/tokenizer', 'prakalpa/parser/meta_grammar', 'prakalpa/parser/main', 'prakalpa/parser/pgen', 'prakalpa/constants/non_terminals', 'dojo/request/xhr', 'dojo/NodeList-manipulate' ], function (declare, lang, query, Tokenizer, metagrammarDFAs, Parser, ParserGenerator, NonTerminals, xhr) { return declare([], { /** * sourceText: Source that needs to be tokenized */ constructor: function (opts) { lang.mixin(this, opts); }, load: function (code, resultEltId) { this.tokenizer = new Tokenizer({ sourceText: code }); this.resultElt = query(resultEltId); this.resultElt.text(''); }, getNextToken: function () { try { this.appendObjectToTextBox(this.tokenizer.getNext()); } catch(e) { this.appendObjectToTextBox(e); } }, appendObjectToTextBox: function (tokenInfo) { var text; text = this.resultElt.text(); text += JSON.stringify(tokenInfo); text += '\\n'; this.resultElt.text(text); }, getAllTokens: function () { var tokenInfo; do { try { tokenInfo = this.tokenizer.getNext(); this.appendObjectToTextBox(tokenInfo); } catch (e) { this.appendObjectToTextBox(e); break; } } while(tokenInfo.token !== 'ENDMARKER'); }, construct_parse_tree: function (pathToGrammarFile, callback) { xhr(pathToGrammarFile) .then(function (pythonGrammar) { callback( new Parser({ grammar: metagrammarDFAs, start: NonTerminals.MSTART, sourceText: pythonGrammar }).parse()); }); }, constructPgen: function (parseTreeRoot) { var pgen; pgen = new ParserGenerator({ parseTreeRoot: parseTreeRoot }); window.nfaGrammar = pgen.nfaGrammar; window.labels = pgen.labels; window.dfaGrammar = pgen.dfaGrammar; } }); }); × Search results Close "},"parser_main.js.html":{"id":"parser_main.js.html","title":"Source: parser/main.js","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Source: parser/main.js /* * Port of cpython's parser, Parser/parser.c, * in particular the PyParser_AddToken function. */ define([ 'dojo/_base/declare', 'dojo/_base/lang', 'dojo/_base/array', 'prakalpa/tokenizer', 'prakalpa/parser/stack', 'prakalpa/parser/parse_tree_node', 'prakalpa/constants/status_codes', 'prakalpa/constants/tokens', 'prakalpa/constants/non_terminals', 'prakalpa/exceptions', ], function (declare, lang, array, Tokenizer, Stack, ParseTreeNode, ParserStatus, Tokens, NonTerminals, Exceptions) { return declare([], { /** * grammar: Dictionary of nonTerminal(key), dfa(value) * start: nonTerminal for start symbol * sourceText: Source that needs to be parsed **/ constructor: function (opts) { var start_symbol_dfa; lang.mixin(this, opts); this.tokenizer = new Tokenizer({ sourceText: this.sourceText }); this.parseTreeRoot = new ParseTreeNode({ symbol: this.start, string: null, lineNum: 0, columnOffset: 0 }); this.stack = new Stack(); start_symbol_dfa = this.grammar[this.start]; this.stack.push({ dfa: start_symbol_dfa, currentParseTreeNode: this.parseTreeRoot, currentState: start_symbol_dfa.states[0] }); this.constructNextTable(); }, constructNextTable: function () { var nonTerminal, dfa, grammar; grammar = this.grammar; for(nonTerminal in grammar) { dfa = grammar[nonTerminal]; array.forEach(dfa.states, function (state) { array.forEach(state.arcs, function (arc) { var firstSet; if(arc.label in NonTerminals) { firstSet = grammar[arc.label].firstSet; array.forEach(firstSet, function (label) { state.next[label] = { arrow: arc.arrow, nonTerminal: arc.label, }; }); } else { state.next[arc.label] = { arrow: arc.arrow, nonTerminal: null }; } }); }); } }, shift: function (parserState, currentParseTreeNode) { var childNode; if(this.stack.isEmpty()) { throw new Error('Stack was not expected to be empty'); } childNode = new ParseTreeNode({ symbol: parserState.terminal || parserState.nonTerminal, lineNum: parserState.lineNum, string: parserState.string, columnOffset: parserState.columnOffset }); currentParseTreeNode.addChild(childNode); this.stack.updateTop('currentState', parserState.endState); return childNode; }, push: function (parserState, currentParseTreeNode) { var childNode; childNode = this.shift(parserState, currentParseTreeNode); this.stack.push({ dfa: parserState.dfa, currentParseTreeNode: childNode, currentState: parserState.dfa.states[0] }); }, parse: function () { var tokenInfo, parseStatus; do { tokenInfo = this.tokenizer.getNext(); if(tokenInfo.token === Tokens.ERRORTOKEN) { return tokenInfo.error; } parseStatus = this.addToken(tokenInfo); if(parseStatus !== ParserStatus.OK &amp;&amp; parseStatus !== ParserStatus.DONE) { return parseStatus; } } while(tokenInfo.token !== Tokens.ENDMARKER); return this.parseTreeRoot; }, addToken: function (tokenInfo) { var stackEntry, dfa, currentState, currentParseTreeNode, transition; for(;;) { stackEntry = this.stack.peek(); dfa = stackEntry.dfa; currentParseTreeNode = stackEntry.currentParseTreeNode; currentState = stackEntry.currentState; if(tokenInfo.token in currentState.next) { transition = currentState.next[tokenInfo.token]; if(transition.nonTerminal) { this.push({ nonTerminal: transition.nonTerminal, dfa: this.grammar[transition.nonTerminal], endState: dfa.states[transition.arrow], lineNum: tokenInfo.lineNum || tokenInfo.start.lineNum }, currentParseTreeNode); continue; } else { this.shift({ terminal: tokenInfo.token, endState: dfa.states[transition.arrow], lineNum: tokenInfo.lineNum || tokenInfo.start.lineNum, string: tokenInfo.string, columnOffset: tokenInfo.start &amp;&amp; tokenInfo.start.column }, currentParseTreeNode); } currentState = this.stack.peek('currentState'); while(currentState &amp;&amp; currentState.isAccepting &amp;&amp; !currentState.arcs.length) { this.stack.pop(); if(this.stack.isEmpty()) { return ParserStatus.DONE; } currentState = this.stack.peek('currentState'); } return ParserStatus.OK; } if(currentState.isAccepting) { this.stack.pop(); if(this.stack.isEmpty()) { throw new Exceptions.SyntaxError(); } continue; } throw new Exceptions.SyntaxError(); } } }); }); × Search results Close "},"parser_parse_tree_node.js.html":{"id":"parser_parse_tree_node.js.html","title":"Source: parser/parse_tree_node.js","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Source: parser/parse_tree_node.js define([ 'dojo/_base/declare', 'dojo/_base/lang' ], function (declare, lang) { return declare([], { /** * symbol: nonTerminal or terminal type * string: value of terminal * lineNum: line number of terminal * columnOffset: column offset of terminal */ constructor: function (opts) { lang.mixin(this, opts); this.children = []; }, addChild: function (child) { this.children.push(child); }, is: function (symbol) { return (this.symbol === symbol); }, getString: function () { return this.string; }, getSymbol: function () { return this.symbol; } }); }); × Search results Close "},"parser_stack.js.html":{"id":"parser_stack.js.html","title":"Source: parser/stack.js","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Source: parser/stack.js define([ 'dojo/_base/declare' ], function (declare) { return declare([Array], { /** * dfa: dfa for a non terminal * currentParseTreeNode: node that is going to be parent of the next child * currentState: active state in dfa */ peek: function (propertyName) { var topEntry; topEntry = this[this.length - 1]; if(propertyName) { return topEntry[propertyName]; } else { return topEntry; } }, isEmpty: function () { return !this.length; }, updateTop: function (propertyName, newValue) { var topEntry; topEntry = this.peek(); topEntry[propertyName] = newValue; } }); }); × Search results Close "},"parser_dfa.js.html":{"id":"parser_dfa.js.html","title":"Source: parser/dfa.js","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Source: parser/dfa.js define([ 'dojo/_base/declare', 'dojo/_base/lang', 'dojo/_base/array', 'prakalpa/parser/dfa_state', 'prakalpa/constants/tokens', 'prakalpa/exceptions' ], function (declare, lang, array, DFAState, Terminals, Exceptions) { var START_MARKER; /** * @class prakalpa.parser.DFA */ return declare([], { /* * @constructor * @param {string} type - NonTerminal constant that represents this DFA * @param {prakalpa.parser.nfa} nfa - The NFA from which the DFA must be constructed */ constructor: function (opts) { lang.mixin(this, opts); this.states = []; this.firstSet = null; this.start = new DFAState(); this.start.addClosure(this.nfa.start); if(this.nfa.start === this.nfa.end) { this.start.setAsEndState(); } this.states.push(this.start); this.generateDFA(this.start); }, generateDFA: function (state) { var arcs, label, dfaState; array.forEach(state.getNFAStates(), function (nfaState) { array.forEach(nfaState, function (arc) { if(arc.label !== Terminals.EMPTY) { state.updateArcDFAState(arc.label, arc.arrow); } }); }); arcs = state.getArcs(); for(label in arcs) { dfaState = arcs[label]; if(dfaState.containsNFAState(this.nfa.end)) { dfaState.setAsEndState(); } if(this.addState(dfaState)) { this.generateDFA(dfaState); } } }, addState: function (dfaState) { var contains, newState; contains = array.filter(this.states, function (state) { return state.equals(dfaState); }); newState = !contains.length; if(newState) { this.states.push(dfaState); } return newState; }, calcFirstSet: function (dfaGrammar) { var visited, result, label; visited = {}; result = {}; if(this.firstSet === START_MARKER) { throw new Exceptions.LeftRecursion(this.dfa.type); } if (this.firstSet) { return this.firstSet; } this.firstSet = START_MARKER; for(label in this.start.arcs) { if(!(label in visited)) { visited[label] = true; if(label in dfaGrammar) { lang.mixin(result, dfaGrammar[label].calcFirstSet(dfaGrammar)); // NonTerminal } else if(label in Terminals){ result[label] = true; // Terminal } } } this.firstSet = result; return this.firstSet; }, }); }); × Search results Close "},"token.js.html":{"id":"token.js.html","title":"Source: token.js","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Source: token.js define([ 'dojo/_base/declare', 'dojo/_base/lang', ], function (declare, lang) { /** * Represents a token * @class prakalpa.token * @property {prakalpa.constants.tokens} type - Type of token * @property {Object} start - The position at which the token starts * @property {number} start.column - The column number in a line at which the token starts * @property {number} start.lineNum - The line number in the source at which the token starts * @property {Object} end - The position just before which the token ends * @property {number} end.column - The column number in a line before which the token ends * @property {number} end.lineNum - The line number in the source before which the token ends * @property {string} string - String value of token */ return declare([], { constructor: function (opts) { lang.mixin(this, opts); } }); }); × Search results Close "},"tokenizer.js.html":{"id":"tokenizer.js.html","title":"Source: tokenizer.js","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Source: tokenizer.js /* * This is a port of cpython's tokenizer, Parser/tokenizer.c, * in particular, the tok_get function. */ define([ 'dojo/_base/declare', 'dojo/_base/lang', 'prakalpa/constants/tokens', 'prakalpa/constants/errors', 'prakalpa/exceptions', 'prakalpa/token' ], function (declare, lang, Tokens, Errors, Exceptions, Token) { var MAXINDENT; MAXINDENT = 100; /** * The tokenizer splits a string into Python tokens * @class prakalpa.Tokenizer * @param opts * @param {String} opts.sourceText - Source that needs to be tokenized */ return declare([], /** @lends prakalpa.Tokenizer.prototype */{ constructor: function (opts) { lang.mixin(this, opts); this.atBeginningOfLine = true; this.level = 0; // Parenthesis nesting level this.indstack = [0]; this.indent = 0; this.pending = 0; this.charIndex = -1; this.startOfToken = {}; this.contLine = false; this.lineNum = 1; this.colNum = -1; this.lines = this.sourceText.split('\\n'); }, /** * Entrypoint into the tokenizer. Returns the next token in the stream * @public * @returns {prakalpa.Token} token - Next token * @throws {prakalpa.Exceptions.TokenizeError} Will throw an error if a syntax errors is encountered */ getNext: function () { return this._nextline(); }, /** * Returns the value of the token starting at position {start} and ending * just before position {end} both columnwise and linewise * @private * @param {Object} start - The position at which the token starts * @param {Number} start.column - The column number in a line at which the token starts * @param {Number} start.lineNum - The line number in the source at which the token starts * @param {Object} end - The position just before which the token ends * @param {Number} end.column - The column number in a line before which the token ends * @param {Number} end.lineNum - The line number in the source before which the token ends * @returns {String} tokenString - String value of token starting at start and ending just before end */ _getString: function (start, end) { var startLine, endLine, startColumn, endColumn, string, i; startColumn = start.column; endColumn = end.column; startLine = start.lineNum - 1; endLine = end.lineNum - 1; if(startLine === endLine) { string = this.lines[startLine].substring(startColumn, endColumn); } else { string = this.lines[startLine].substring(startColumn); for(i = startLine + 1; i &lt; endLine - 1; i++) { string += this.lines[i] + '\\n'; } string += this.lines[i].substring(0, endColumn); } return string; }, /** * Get the next character in the stream and keep track of line number and * column number * @private * @returns {String} nextChar - Next character in the source text */ _getNextChar: function () { if(this.sourceText[this.charIndex] === '\\n') { this.lineNum++; this.colNum = -1; } this.charIndex++; this.colNum++; if(this.charIndex &gt;= this.sourceText.length) { return; } return this.sourceText[this.charIndex]; }, /** * Go back one character in the stream while accounting for newlines * @private */ _backupOneChar: function () { if(this.charIndex === -1) { return; } this.charIndex--; this.colNum--; if(this.sourceText[this.charIndex] === '\\n') { this.lineNum--; } }, _nextline: function () { this.startOfToken = { column: 0, lineNum: this.lineNum }; this.blankline = false; if(this.atBeginningOfLine) { this.atBeginningOfLine = false; this._countIndentsAndDedents(); } this.startOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; if(this.pending !== 0) { if(this.pending &lt; 0) { this.pending++; return { type: Tokens.DEDENT, lineNum: this.lineNum }; } else { this.pending--; return { type: Tokens.INDENT, lineNum: this.lineNum }; } } // TODO Add support for async return this._again(); }, _verifyIdentifier: function () { // TODO Add support for Unicode return false; }, _processNames: function (c) { var nonascii, saw_b, saw_r, saw_u, endOfToken; nonascii = false; saw_b = saw_r = saw_u = false; while(true) { if(!(saw_b || saw_u) &amp;&amp; (c === 'b' || c === 'B')) { saw_b = true; } else if(!(saw_b || saw_u || saw_r) &amp;&amp; (c === 'u' || c === 'U')) { saw_u = true; } else if(!(saw_r || saw_u) &amp;&amp; (c === 'r' || c === 'R')) { saw_r = true; } else { break; } c = this._getNextChar(); if(c === '&quot;' || c === &quot;'&quot;) { return this._letterQuote(c); } } while (this._isPotentialIdentifierChar(c)) { if(c.charCodeAt(0) &gt;= 128) { nonascii = true; } c = this._getNextChar(); } this._backupOneChar(); if(nonascii &amp;&amp; !this._verifyIdentifier()) { throw new Exceptions.TokenizeError({ message: Errors.TOKEN, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } //TODO Add support for async endOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; return Token({ type: Tokens.NAME, start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); }, _again: function () { var c, endOfToken; //TODO Add support for tabs and form feeds do { c = this._getNextChar(); } while (c === ' '); this.startOfToken = { column: this.colNum, lineNum: this.lineNum }; if(c === '#') { while (c &amp;&amp; c !== '\\n') { c = this._getNextChar(); } } if(!c) { return { type: Tokens.ENDMARKER, lineNum: this.lineNum }; } if(this._isPotentialIdentifierStart(c)) { return this._processNames(c); } if(c === '\\n') { this.atBeginningOfLine = true; if(this.blankline || this.level &gt; 0) { return this._nextline(); } this.contLine = false; endOfToken = { column: this.colNum, lineNum: this.lineNum }; return Token({ type: Tokens.NEWLINE, start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); } return this._startWithPeriod(c); }, _startWithPeriod: function (c) { var endOfToken; if(c === '.') { c = this._getNextChar(); if(this._isDigit(c)) { return this._fraction(); } else if(c === '.') { c = this._getNextChar(); if(c === '.') { endOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; return Token({ type: Tokens.ELLIPSIS, start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); } else { this._backupOneChar(); } this._backupOneChar(); } else { this._backupOneChar(); } endOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; return Token({ type: Tokens.DOT, start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); } return this._isNumber(c); }, _isNumber: function (c) { var nonZero, charCode, endOfToken; if(this._isDigit(c)) { if(c === '0') { c = this._getNextChar(); if(c === '.') { return this._fraction(); } if(c === 'j' || c === 'J') { return this._imaginary(); } if(c === 'x' || c === 'X') { c = this._getNextChar(); if(!this._isXDigit(c)) { this._backupOneChar(); throw new Exceptions.TokenizeError({ message: Errors.TOKEN, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } do { c = this._getNextChar(); } while(this._isXDigit(c)); } else if(c === 'o' || c === 'O') { c = this._getNextChar(); charCode = c.charCodeAt(0); if(charCode &lt; 48 || charCode &gt;= 56) { // Only '0' to '7' are allowed this._backupOneChar(); throw new Exceptions.TokenizeError({ message: Errors.TOKEN, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } do { c = this._getNextChar(); } while (c &amp;&amp; 48 &lt;= c.charCodeAt(0) &amp;&amp; c.charCodeAt(0) &lt; 56); } else if(c === 'b' || c === 'B') { c = this._getNextChar(); if(c !== '0' &amp;&amp; c !== '1') { this._backupOneChar(); throw new Exceptions.TokenizeError({ message: Errors.TOKEN, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } do { c = this._getNextChar(); } while (c === '0' || c === '1'); } else { nonZero = false; while(c === '0') { c = this._getNextChar(); } while(this._isDigit(c)) { nonZero = true; c = this._getNextChar(); } if(c === '.') { return this._fraction(); } else if(c === 'e' || c === 'E') { return this._exponent(); } else if(c === 'j' || c === 'J') { return this._imaginary(); } else if (nonZero) { this._backupOneChar(); throw new Exceptions.TokenizeError({ message: Errors.TOKEN, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } } } else { do { c = this._getNextChar(); } while (this._isDigit(c)); if(c === '.') { return this._fraction(); } if(c === 'e' || c === 'E') { return this._exponent(); } if(c === 'j' || c === 'J') { return this._imaginary(); } } this._backupOneChar(); endOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; return Token({ type: Tokens.NUMBER, start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); } return this._letterQuote(c); }, _fraction: function (c) { var endOfToken; do { c = this._getNextChar(); } while (this._isDigit(c)); if(c === 'e' || c === 'E') { return this._exponent(); } if(c === 'j' || c === 'J') { return this._imaginary(); } this._backupOneChar(); endOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; return Token({ type: Tokens.NUMBER, start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); }, _exponent: function () { var c, endOfToken; c = this._getNextChar(); if(c === '+' || c === '-') { c = this._getNextChar(); if(!this._isDigit(c)) { this._backupOneChar(); throw new Exceptions.TokenizeError({ message: Errors.TOKEN, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } } else if(!this._isDigit(c)) { this._backupOneChar(); this._backupOneChar(); endOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; return Token({ type: Tokens.NUMBER, start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); } do { c = this._getNextChar(); } while(this._isDigit(c)); if(c === 'j' || c === 'J') { return this._imaginary(); } this._backupOneChar(); endOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; return Token({ type: Tokens.NUMBER, start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); }, _imaginary: function () { var endOfToken; endOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; return Token({ type: Tokens.NUMBER, start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); }, _letterQuote: function (c) { var quote, quoteSize, endQuoteSize, endOfToken; if(c === '&quot;' || c === &quot;'&quot;) { quote = c; quoteSize = 1; endQuoteSize = 0; c = this._getNextChar(); if(c === quote) { c = this._getNextChar(); if(c === quote) { quoteSize = 3; } else { endQuoteSize = 1; } } if(c !== quote) { this._backupOneChar(); } while(endQuoteSize !== quoteSize) { c = this._getNextChar(); if(!c) { if(quoteSize === 3) { throw new Exceptions.TokenizeError({ message: Errors.EOFS, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } else { throw new Exceptions.TokenizeError({ message: Errors.EOLS, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } } if(quoteSize === 1 &amp;&amp; c === '\\n') { throw new Exceptions.TokenizeError({ message: Errors.EOLS, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } if(c === quote) { endQuoteSize += 1; } else { endQuoteSize = 0; if(c === '\\\\') { c = this._getNextChar(); } } } endOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; return Token({ type: Tokens.STRING, start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); } return this._lineContinuation(c); }, _lineContinuation: function (c) { if(c === '\\\\') { c = this._getNextChar(); if(c !== '\\n') { throw new Exceptions.TokenizeError({ message: Errors.LINECONT, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } this.contLine = true; return this._again(); } return this._twoCharacter(c); }, _twoCharacter: function (c) { var c2, c3, token, token3, endOfToken; c2 = this._getNextChar(); token = this.twoCharToken(c, c2); if(token !== Tokens.OP) { c3 = this._getNextChar(); token3 = this.threeCharToken(c, c2, c3); if(token3 !== Tokens.OP) { token = token3; } else { this._backupOneChar(); } endOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; return Token({ type: token, start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); } this._backupOneChar(); return this._parenthesesCheck(c); }, _parenthesesCheck: function (c) { switch(c) { case '(': case '[': case '{': this.level++; break; case ')': case ']': case '}': this.level--; break; } return this._oneCharacter(c); }, _oneCharacter: function (c) { var endOfToken; endOfToken = { column: this.colNum + 1, lineNum: this.lineNum }; return Token({ type: this.oneCharToken(c), start: this.startOfToken, end: endOfToken, string: this._getString(this.startOfToken, endOfToken) }); }, _isPotentialIdentifierStart: function (c) { var code; if(typeof(c) === 'undefined') { return false; } code = c.charCodeAt(0); return ((code &gt; 64 &amp;&amp; code &lt; 91) || // Uppercase (code &gt; 96 &amp;&amp; code &lt; 123) || // Lowercase (code &gt;= 128) || // More than ASCII (c === '_')); }, _isPotentialIdentifierChar: function (c) { var code; if(typeof(c) === 'undefined') { return false; } code = c.charCodeAt(0); return ((code &gt; 64 &amp;&amp; code &lt; 91) || // Uppercase (code &gt; 96 &amp;&amp; code &lt; 123) || // Lowercase (code &gt; 47 &amp;&amp; code &lt; 58) || // Digit (code &gt;= 128) || // More than ASCII (c === '_')); }, _countIndentsAndDedents: function () { var col, c; col = 0; // Supporting only whitespace for now. // TODO Add support for tabs and form-feed c = this._getNextChar(); while(c === ' ') { col++; c = this._getNextChar(); } this._backupOneChar(); // TODO Add support for interactive mode if(c === '\\#' || c === '\\n') { this.blankline = true; } // I think altcol, altindstack etc. are to check if tabs and spaces // are being used inconsistently in indentation. // As we don't support tabs anyway, I'm skipping that part of the code if(!this.blankline &amp;&amp; this.level === 0) { if(col &gt; this.indstack[this.indent]) { if(this.indent + 1 &gt;= MAXINDENT) { throw new Exceptions.TokenizeError({ message: Errors.TOODEEP, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } this.pending++; this.indstack[++this.indent] = col; } else if (col &lt; this.indstack[this.indent]) { while(this.indent &gt; 0 &amp;&amp; col &lt; this.indstack[this.indent]) { this.pending--; this.indent--; } if(col !== this.indstack[this.indent]) { throw new Exceptions.TokenizeError({ message: Errors.DEDENT, type: Tokens.ERRORTOKEN, lineNum: this.lineNum }); } } } }, _isDigit: function (c) { var charCode; if(typeof(c) === 'undefined') { return false; } charCode = c.charCodeAt(0); return (charCode &gt; 47 &amp;&amp; charCode &lt; 58); }, _isXDigit: function (c) { var charCode; if(typeof(c) === 'undefined') { return false; } charCode = c.charCodeAt(0); return (this._isDigit(c) || (charCode &gt;= 65 &amp;&amp; charCode &lt;= 70) || // A to F (charCode &gt;= 97 &amp;&amp; charCode &lt;= 102)); // a to f }, /** * Returns token corresponding to one character string * @public * @param {string} c - One character string * @returns {prakalpa.constants.Tokens} */ oneCharToken: function (c) { switch (c) { case '(': return Tokens.LPAR; case ')': return Tokens.RPAR; case '[': return Tokens.LSQB; case ']': return Tokens.RSQB; case ':': return Tokens.COLON; case ',': return Tokens.COMMA; case ';': return Tokens.SEMI; case '+': return Tokens.PLUS; case '-': return Tokens.MINUS; case '*': return Tokens.STAR; case '/': return Tokens.SLASH; case '|': return Tokens.VBAR; case '&amp;': return Tokens.AMPER; case '&lt;': return Tokens.LESS; case '&gt;': return Tokens.GREATER; case '=': return Tokens.EQUAL; case '.': return Tokens.DOT; case '%': return Tokens.PERCENT; case '{': return Tokens.LBRACE; case '}': return Tokens.RBRACE; case '^': return Tokens.CIRCUMFLEX; case '~': return Tokens.TILDE; case '@': return Tokens.AT; default: return Tokens.OP; } }, /** * Returns token corresponding to two character string * @public * @param {string} c1 - First character * @param {string} c2 - Second character * @returns {prakalpa.constants.Tokens} */ twoCharToken: function (c1, c2) { switch (c1) { case '=': switch (c2) { case '=': return Tokens.EQEQUAL; } break; case '!': switch (c2) { case '=': return Tokens.NOTEQUAL; } break; case '&lt;': switch (c2) { case '&gt;': return Tokens.NOTEQUAL; case '=': return Tokens.LESSEQUAL; case '&lt;': return Tokens.LEFTSHIFT; } break; case '&gt;': switch (c2) { case '=': return Tokens.GREATEREQUAL; case '&gt;': return Tokens.RIGHTSHIFT; } break; case '+': switch (c2) { case '=': return Tokens.PLUSEQUAL; } break; case '-': switch (c2) { case '=': return Tokens.MINEQUAL; case '&gt;': return Tokens.RARROW; } break; case '*': switch (c2) { case '*': return Tokens.DOUBLESTAR; case '=': return Tokens.STAREQUAL; } break; case '/': switch (c2) { case '/': return Tokens.DOUBLESLASH; case '=': return Tokens.SLASHEQUAL; } break; case '|': switch (c2) { case '=': return Tokens.VBAREQUAL; } break; case '%': switch (c2) { case '=': return Tokens.PERCENTEQUAL; } break; case '&amp;': switch (c2) { case '=': return Tokens.AMPEREQUAL; } break; case '^': switch (c2) { case '=': return Tokens.CIRCUMFLEXEQUAL; } break; case '@': switch (c2) { case '=': return Tokens.ATEQUAL; } break; } return Tokens.OP; }, /** * Returns token corresponding to three character string * @public * @param {string} c1 - First character * @param {string} c2 - Second character * @param {string} c3 - Third character * @returns {prakalpa.constants.Tokens} */ threeCharToken: function (c1, c2, c3) { switch (c1) { case '&lt;': switch (c2) { case '&lt;': switch (c3) { case '=': return Tokens.LEFTSHIFTEQUAL; } break; } break; case '&gt;': switch (c2) { case '&gt;': switch (c3) { case '=': return Tokens.RIGHTSHIFTEQUAL; } break; } break; case '*': switch (c2) { case '*': switch (c3) { case '=': return Tokens.DOUBLESTAREQUAL; } break; } break; case '/': switch (c2) { case '/': switch (c3) { case '=': return Tokens.DOUBLESLASHEQUAL; } break; } break; case '.': switch (c2) { case '.': switch (c3) { case '.': return Tokens.ELLIPSIS; } break; } break; } return Tokens.OP; } }); }); × Search results Close "},"global.html":{"id":"global.html","title":"Global","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Global Methods constructor() sourceText: Source that needs to be tokenized Source: main.js, line 18 constructor() grammar: Dictionary of nonTerminal(key), dfa(value)start: nonTerminal for start symbolsourceText: Source that needs to be parsed Source: parser/main.js, line 24 constructor() symbol: nonTerminal or terminal typestring: value of terminallineNum: line number of terminalcolumnOffset: column offset of terminal Source: parser/parse_tree_node.js, line 12 peek() dfa: dfa for a non terminalcurrentParseTreeNode: node that is going to be parent of the next childcurrentState: active state in dfa Source: parser/stack.js, line 10 × Search results Close "},"classes.list.html":{"id":"classes.list.html","title":"Classes","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Classes Classes DFA token Tokenizer × Search results Close "},"index.html":{"id":"index.html","title":"Index","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek × Search results Close "},"prakalpa.parser.DFA.html":{"id":"prakalpa.parser.DFA.html","title":"Class: DFA","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Class: DFA DFA new DFA() Source: parser/dfa.js, line 11 × Search results Close "},"prakalpa.token.html":{"id":"prakalpa.token.html","title":"Class: token","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Class: token token new token() Represents a token Properties: Name Type Description type prakalpa.constants.tokens Type of token start Object The position at which the token starts Properties Name Type Description column number The column number in a line at which the token starts lineNum number The line number in the source at which the token starts end Object The position just before which the token ends Properties Name Type Description column number The column number in a line before which the token ends lineNum number The line number in the source before which the token ends string string String value of token Source: token.js, line 5 × Search results Close "},"prakalpa.Tokenizer.html":{"id":"prakalpa.Tokenizer.html","title":"Class: Tokenizer","body":" Prakalpa Classes prakalpa.parser.DFAprakalpa.tokenprakalpa.Tokenizer Global constructorpeek Class: Tokenizer Tokenizer new Tokenizer(opts) The tokenizer splits a string into Python tokens Parameters: Name Type Description opts Properties Name Type Description sourceText String Source that needs to be tokenized Source: tokenizer.js, line 17 Methods &lt;private&gt; _backupOneChar() Go back one character in the stream while accounting for newlines Source: tokenizer.js, line 102 &lt;private&gt; _getNextChar() Get the next character in the stream and keep track of line number andcolumn number Source: tokenizer.js, line 87 Returns: nextChar - Next character in the source text Type String &lt;private&gt; _getString(start, end) Returns the value of the token starting at position {start} and endingjust before position {end} both columnwise and linewise Parameters: Name Type Description start Object The position at which the token starts Properties Name Type Description column Number The column number in a line at which the token starts lineNum Number The line number in the source at which the token starts end Object The position just before which the token ends Properties Name Type Description column Number The column number in a line before which the token ends lineNum Number The line number in the source before which the token ends Source: tokenizer.js, line 61 Returns: tokenString - String value of token starting at start and ending just before end Type String getNext() Entrypoint into the tokenizer. Returns the next token in the stream Source: tokenizer.js, line 45 Throws: Will throw an error if a syntax errors is encountered Type prakalpa.Exceptions.TokenizeError Returns: token - Next token Type prakalpa.Token oneCharToken(c) Returns token corresponding to one character string Parameters: Name Type Description c string One character string Source: tokenizer.js, line 691 Returns: Type prakalpa.constants.Tokens threeCharToken(c1, c2, c3) Returns token corresponding to three character string Parameters: Name Type Description c1 string First character c2 string Second character c3 string Third character Source: tokenizer.js, line 812 Returns: Type prakalpa.constants.Tokens twoCharToken(c1, c2) Returns token corresponding to two character string Parameters: Name Type Description c1 string First character c2 string Second character Source: tokenizer.js, line 727 Returns: Type prakalpa.constants.Tokens × Search results Close "}}
    </script>

    <script type="text/javascript">
        $(document).ready(function() {
            Searcher.init();
        });

        $(window).on("message", function(msg) {
            var msgData = msg.originalEvent.data;

            if (msgData.msgid != "docstrap.quicksearch.start") {
                return;
            }

            var results = Searcher.search(msgData.searchTerms);

            window.parent.postMessage({"results": results, "msgid": "docstrap.quicksearch.done"}, "*");
        });
    </script>
</body>
</html>
